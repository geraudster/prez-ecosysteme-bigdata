#+TITLE:     L'écosystème Big Data en 2019
#+AUTHOR:    Géraud Dugé de Bernonville
#+EMAIL:     geraud.dugedebernonville@zenika.com
#+REVEAL_ROOT: https://cdn.jsdelivr.net/npm/reveal.js@3.7.0/
#+OPTIONS: toc:1 num:nil
#+LANGUAGE: fr
#+REVEAL_HLEVEL: 2
#+REVEAL_THEME: beige

* Three Big

- Big Model
- Big Data
- Big Compute

** Big Model

Deep Learning

#+ATTR_REVEAL: :frag (t)
    * Recommender Systems
    * NLP
    * Timeseries

*** Nombreux outils

TF, Keras, PyTorch, Spark (BigDL de Intel), DL4J

*** Machine Learning Engineer

Entre Data Engineer et Data Scientist
- viennent de l'engineer et connaissent le Machine Learning
- déploiement en prod

Vient du fait que les Data Scientist n'ont pas d'outils pour déployer en prod

Clipper project => aide au déploiement (prend un notebook et le transform en dat aproduct)

** Big Data

bottleneck : quality and amount of training data

*** If big Data is the new oil...

#+BEGIN_QUOTE
#+ATTR_REVEAL: :frag appear
...training data is the NEW new oil
#+END_QUOTE

*** Unsupervised data

- trouver des regroupements
- réduction de dimension
- détection d'anomalies
- => générer des données similaires (GANs)

*** Pourquoi générer des données

- moins cher (pas la peine de payer des gens pour labeliser)
- on apprend de ses données
- permet de générer des scénarios, des simulations (par ex: voiture autonome)


*** Outils

GAN, Variational Autoenoders, others

*** Weak Supervised

Entre unsupervised et supervised
Weak => moins de données labellisées, les sources:
- Heuristics, avec des experts du domaine
- Crowdsourcing
- Boosting
- distant supervision

Data Programming: Creating Large Training Sets, Quickly

Snorkel

*** Realtime / Streaming

Amplab : Spark, Alluxio

Batch data -> Analytics

RISE lab : live data, realtime decision

Offline learning vs continuous learning

Reinforcement learning

In IoT, stream processing de données de devices, recalcul de modèles en temps reél (robotique)

=> simulations, graph de calcul qui évolue, faible latence


** Big Compute

Scale, Throughput (high volume), Latency (fast answer), Power consumption

Machine Learning infrastrucure :
- open source software
- matos héterogene
- Hardware
- réseau

Pour le Deep Learning:
- matos pour l'entrainement (GPU)
- matos pour l'inference (CPU or other)

ASIC pour inférence (latence est plus importante que le throughput)

Microsoft FPGA (Intel / Altera) pour l'inférence, Project Catapult

Nvidia Volta, bonne perf training et inférence avec faible consommation

Training dans le cloud, inference on the edge

En cours: compute on the edge

Federated learning (securité, privacy), collaborative machine learning

** Wrap up

Côté IA: fairness, interpretability, privacy

* Source

https://learning.oreilly.com/videos/trends-in-ai/9781491996409/9781491996409-video313324

